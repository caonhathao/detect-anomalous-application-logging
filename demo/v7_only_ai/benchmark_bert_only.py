import os
import sys
import glob
import time
import numpy as np
from tqdm import tqdm
from dotenv import load_dotenv
from pathlib import Path

# ThÃªm Ä‘Æ°á»ng dáº«n root Ä‘á»ƒ import Ä‘Æ°á»£c cÃ¡c module trong src
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

from src import LogBertAnalyzer, parsing_http_requests, process_log_string

# ================= CONFIG =================
load_dotenv()
LOG_FOLDER = os.getenv("LOG_FOLDER", "logs") # Äáº£m báº£o file .env cÃ³ biáº¿n nÃ y hoáº·c sá»­a trá»±c tiáº¿p
VOCAB_SIZE = 3551
CONFIDENCE_THRESHOLD = 0.05  # NgÆ°á»¡ng giá»‘ng trong analyzer.py

# ================= HELPER FUNCTIONS (Copy tá»« analyzer.py) =================
def split_requests_rfc(content, filename):
    """TÃ¡ch request vÃ  láº¥y nhÃ£n Ground Truth tá»« file log"""
    reqs = []
    labels = [] # List chá»©a nhÃ£n 'safe' hoáº·c 'malicious'
    current = []
    
    lines = content.splitlines()
    is_malicious = False
    
    # Biáº¿n táº¡m Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhÃ£n cá»§a block hiá»‡n táº¡i
    current_label = "safe" 

    for line in lines:
        if line.strip() in ("SAFE|", "MALICIOUS|"):
            # LÆ°u block cÅ©
            if current:
                reqs.append("\n".join(current).strip())
                labels.append(current_label)
                current = []
            
            # Cáº­p nháº­t nhÃ£n má»›i
            if line.strip() == "MALICIOUS|":
                current_label = "malicious"
            else:
                current_label = "safe"
        else:
            current.append(line)

    # Block cuá»‘i
    if current:
        reqs.append("\n".join(current).strip())
        labels.append(current_label)

    return reqs, labels

# ================= MAIN BENCHMARK =================
def main():
    print(f"ðŸš€ Äang khá»Ÿi táº¡o LogBERT Analyzer (Vocab: {VOCAB_SIZE})...")
    try:
        analyzer = LogBertAnalyzer(vocab_size=VOCAB_SIZE)
    except Exception as e:
        print(f"âŒ Lá»—i load model: {e}")
        return

    # Láº¥y danh sÃ¡ch file log gá»‘c
    if not os.path.exists(LOG_FOLDER):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c log: {LOG_FOLDER}")
        return

    log_files = sorted(Path(LOG_FOLDER).glob("*.txt"))
    print(f"ðŸ“‚ TÃ¬m tháº¥y {len(log_files)} file log Ä‘á»ƒ test.")

    # Thá»‘ng kÃª
    stats = {"TP": 0, "TN": 0, "FP": 0, "FN": 0}
    total_time = 0
    total_requests = 0

    print("\nðŸ”„ Báº¯t Ä‘áº§u cháº¡y Benchmark...")
    
    # Duyá»‡t qua tá»«ng file log
    for file_path in tqdm(log_files, desc="Processing Files"):
        try:
            content = file_path.read_text(errors="ignore")
            requests, labels = split_requests_rfc(content, file_path.name)
            
            # Duyá»‡t qua tá»«ng request trong file
            for i, req_text in enumerate(requests):
                gt_label = labels[i] # safe / malicious
                
                # --- Báº®T Äáº¦U ÄO THá»œI GIAN Xá»¬ LÃ Cá»¦A BERT ---
                start_time = time.time()
                
                # 1. Preprocessing (Text -> Event IDs)
                # MÃ´ phá»ng láº¡i logic cá»§a process_single_file
                event_ids = []
                # Giáº£ láº­p ghi ra file rá»“i Ä‘á»c láº¡i dÃ²ng (hoáº·c parse trá»±c tiáº¿p string)
                # á»ž Ä‘Ã¢y ta parse trá»±c tiáº¿p string cho nhanh
                log_lines = list(parsing_http_requests(req_text.splitlines()))
                for log_string in log_lines:
                    result = process_log_string(log_string)
                    if result.get("EventId"):
                        event_ids.append(result.get("EventId"))
                
                if not event_ids:
                    continue # Bá» qua náº¿u khÃ´ng parse Ä‘Æ°á»£c ID nÃ o

                # 2. Prediction
                detection_result = analyzer.detect_anomalies(event_ids, confidence_threshold=CONFIDENCE_THRESHOLD)
                
                # Logic xÃ¡c Ä‘á»‹nh malicious giá»‘ng analyzer.py
                # (Náº¿u dÃ²ng cuá»‘i cÃ¹ng hoáº·c báº¥t ká»³ dÃ²ng nÃ o trong cá»­a sá»• bá»‹ Ä‘Ã¡nh dáº¥u lÃ  anomaly)
                # á»ž Ä‘Ã¢y ta láº¥y logic: CÃ³ báº¥t ká»³ anomaly nÃ o trong request nÃ y -> Malicious
                is_predicted_malicious = len(detection_result.get("anomalies", [])) > 0
                
                end_time = time.time()
                # --- Káº¾T THÃšC ÄO ---

                total_time += (end_time - start_time)
                total_requests += 1

                pred_label = "malicious" if is_predicted_malicious else "safe"

                # 3. Update Confusion Matrix
                if gt_label == "malicious" and pred_label == "malicious":
                    stats["TP"] += 1
                elif gt_label == "safe" and pred_label == "safe":
                    stats["TN"] += 1
                elif gt_label == "safe" and pred_label == "malicious":
                    stats["FP"] += 1
                elif gt_label == "malicious" and pred_label == "safe":
                    stats["FN"] += 1

        except Exception as e:
            print(f"âš ï¸ Lá»—i xá»­ lÃ½ file {file_path.name}: {e}")

    # ================= REPORT =================
    TP, TN, FP, FN = stats["TP"], stats["TN"], stats["FP"], stats["FN"]
    total = TP + TN + FP + FN
    
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    accuracy = (TP + TN) / total if total > 0 else 0
    avg_latency = (total_time / total_requests) * 1000 if total_requests > 0 else 0 # ms

    print("\n" + "="*40)
    print("ðŸ“Š Káº¾T QUáº¢ BENCHMARK (BERT ONLY)")
    print("="*40)
    print(f"Total Requests: {total}")
    print(f"Avg Latency:    {avg_latency:.2f} ms/request")
    print("-" * 40)
    print(f"Confusion Matrix:")
    print(f"TP: {TP} | FP: {FP}")
    print(f"FN: {FN} | TN: {TN}")
    print("-" * 40)
    print(f"Accuracy:  {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1-Score:  {f1_score:.4f}")
    print("="*40)

if __name__ == "__main__":
    main()